# Yet another URL shortner

Сервис, предоставляющий API для создания сокращенных ссылок.


## Генерируемые ссылки
Требования к ссылке:
* уникальная (на один оригинальный URL ссылается только одна сокращенная ссылка)
* длиной 10 символов
* состоит из символов латинского алфавита в нижнем и верхнем регистре, цифр и символа '_'

С требованиями все круто, кроме ограничения на длину в 10 символов. Ни больше, ни меньше, ровно 10 )

Еще было написано про простоту в понимании, а вот про невозможность легкого подбора соседних (следующей/предыдущей) коротких ссылок не было ничего сказано.
Поэтому вместо хэширования строки был выбран алгоритм генерации уникальных ID и последующая их конвертация в base63.
Этот подход имеет массу преимуществ:
* Реально прост в реализации (не надо думать про функции хэширования, избавление от коллизий и необходимость генерировать хэш определенной длины)
* Можно легко подогнать под требования по длине (сдвиг даты в алгоритме snowflake позволяет генерировать уникальные ID длиной 10 символов, хотя через какое-то время они, конечно, станут длиннее)
* Алгоритм легко параллелится на множество машин без необходимости синхронизации между ними (бенчмарк показывает, что можно сгенерировать и сконвертировать около 800к уникальных ID за секунду (если я правильно все сделал и посчитал))
* Генерация числового ID позволяет быстро искать его в БД

Из минусов можно отметить только возможность относительно легкого подбора соседних коротких ссылок, т.к. они генерируются последовательно.

## Ручки
Требования по **http**-запросам:
* Метод **Post**, который сохраняет оригинальный URL в базе и возвращает сокращенный
* Метод **Get**, который принимает сокращенный URL и возвращает оригинальный 

И примерно то же самое по **gRPC**.

Что получилось:

### Request
```http request
POST /api/v1/data/shorten
Content-Type: application/json
```
```json
{
  "url": "длинная_ссылка"
}
```
### Response
```json
{
  "shorten_url": "короткая_ссылка"
}
```
<br>

### Request
```http request
POST /api/v1/{shortURL}
```
### Response
```json
{
  "orig_url": "длинная_ссылка"
}
```
## Потыкать палкой

Для генерации proto:
```shell
protoc -I ./api --go_out ./pkg/api --go_opt paths=source_relative --go-grpc_out ./pkg/api --go-grpc_opt paths=source_relative api/api.proto
```

Для запуска тестов:
```shell
go test ./... -v
```

Для запуска бенчмарков:
```shell
go test -run ^$ -bench . -benchmem -count=4 ./...
```

Для создания короткого URL:
```shell
curl -i -X POST -H "Content-Type: application/json" -d '{"url": "123"} ' http://0.0.0.0:8000/api/v1/data/shorten
```

Для получения оригинального URL:
```shell
curl -i -X GET http://0.0.0.0:8000/api/v1/11EPUTq5pA
```

Запуск (конфиги в .env):
```shell
docker compose up --build
```

## Послесловие
Что не успел сделать, но правда-правда хотел:
* Написать тесты. Сделал только тесты на конвертер в base63, а также бенчи на генерацию и перекодирование, работает быстро, хотя snowflake, который я самостоятельно писать не стал выдает примерно в 4 раза меньше предельных 4к ID/миллисекунду.
* Было бы круто написать стресс-тесты на ручки и посмотреть как быстро работает все вместе.
* Postgres можно ускорить добавлением индекса на колонку orig